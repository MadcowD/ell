<!DOCTYPE html>

<html :class="{'dark': darkMode === 'dark' || (darkMode === 'system' &amp;&amp; window.matchMedia('(prefers-color-scheme: dark)').matches)}" class="scroll-smooth" data-content_root="../" lang="en" x-data="{ darkMode: localStorage.getItem('darkMode') || localStorage.setItem('darkMode', 'system'), activeSection: '' }" x-init="$watch('darkMode', val =&gt; localStorage.setItem('darkMode', val))">
<head>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta charset="utf-8"/>
<meta content="white" media="(prefers-color-scheme: light)" name="theme-color"/>
<meta content="black" media="(prefers-color-scheme: dark)" name="theme-color"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<title>@ell.simple | ell  documentation</title>
<meta content="@ell.simple | ell  documentation" property="og:title"/>
<meta content="@ell.simple | ell  documentation" name="twitter:title"/>
<link href="../_static/pygments.css?v=5cc6ec80" rel="stylesheet" type="text/css"/>
<link href="../_static/theme.css?v=ecdfb4fc" rel="stylesheet" type="text/css"/>
<link href="../_static/autodoc_pydantic.css" rel="stylesheet" type="text/css"/>
<link href="../_static/favicon.ico" rel="icon"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="versioning_and_storage.html" rel="next" title="Versioning &amp; Tracing"/>
<link href="../getting_started.html" rel="prev" title="Getting Started"/>
<script>
    <!-- Prevent Flash of wrong theme -->
      const userPreference = localStorage.getItem('darkMode');
      let mode;
      if (userPreference === 'dark' || window.matchMedia('(prefers-color-scheme: dark)').matches) {
        mode = 'dark';
        document.documentElement.classList.add('dark');
      } else {
        mode = 'light';
      }
      if (!userPreference) {localStorage.setItem('darkMode', mode)}
    </script>

<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-220ZB10X27"></script>
<script>
  if (window.location.hostname !== 'localhost' && window.location.hostname !== '127.0.0.1') {
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-220ZB10X27');
  }
</script>
<style>
    .rounded-image {
        border-radius: 10px;
        overflow: hidden;
    }

</style>
<script>
function invertImage(dark) {
    var images = document.querySelectorAll('.invertible-image img');
    var htmlElement = document.documentElement;
    images.forEach(function(image) {
        if (!dark) {
            image.style.filter = 'invert(100%) hue-rotate(160deg)';
        } else {
            image.style.filter = 'none';
        }
    });
}



// Run when the 'dark' class is added or removed from the <html> element
const htmlElement = document.documentElement;

// Use MutationObserver to detect changes in the class attribute
const observer = new MutationObserver((mutations) => {
console.log(document.documentElement.classList)
    mutations.forEach((mutation) => {
            invertImage(document.documentElement.classList.contains('dark'));

    });
});

observer.observe(htmlElement, { attributes: true, attributeFilter: ['class'] });
</script>

<meta content="https://docs.ell.so/" property="og:url"/>
<meta content="ell is a lightweight prompt engineering library treating prompts as functions. It provides tools for versioning, monitoring, and visualization of language model programs." property="og:description"/>
<meta content="https://docs.ell.so/_static/og2.png" property="og:image"/>

<meta content="summary_large_image" property="twitter:card"/>
<meta content="ell is a lightweight prompt engineering library treating prompts as functions. It provides tools for versioning, monitoring, and visualization of language model programs." property="twitter:description"/>

<meta content="ell is a lightweight prompt engineering library treating prompts as functions. It provides tools for versioning, monitoring, and visualization of language model programs." name="description"/>
<meta content="ell, language model programming, prompt engineering, LLM, AI, machine learning, GPT" name="keywords"/>
<meta content="William Guss" name="author"/>
</head>
<body :class="{ 'overflow-hidden': showSidebar }" class="min-h-screen font-sans antialiased bg-background text-foreground" x-data="{ showSidebar: false }">
<div @click.self="showSidebar = false" class="fixed inset-0 z-50 overflow-hidden bg-background/80 backdrop-blur-sm md:hidden" x-cloak="" x-show="showSidebar"></div><div class="relative flex flex-col min-h-screen" id="page"><a class="absolute top-0 left-0 z-[100] block bg-background p-4 text-xl transition -translate-x-full opacity-0 focus:translate-x-0 focus:opacity-100" href="#content">
      Skip to content
    </a><header class="sticky top-0 z-40 w-full border-b shadow-sm border-border supports-backdrop-blur:bg-background/60 bg-background/95 backdrop-blur"><div class="container flex items-center h-14">
<div class="hidden mr-4 md:flex">
<a class="flex items-center mr-6" href="../index.html">
<img alt="Logo" class="mr-2 hidden dark:block" height="24" src="../_static/ell-wide-dark.png" width="120"/>
<img alt="Logo" class="mr-2 dark:hidden" height="24" src="../_static/ell-wide-light.png" width="120"/></a>
<nav class="flex items-center space-x-6 text-sm font-medium">
<a class="transition-colors hover:text-foreground/80 text-foreground/60" href="../index.html">Docs</a>
<a class="transition-colors hover:text-foreground/80 text-foreground/60" href="../reference/index.html">API Reference</a>
<a class="transition-colors hover:text-foreground/80 text-foreground/60" href="https://jobs.ell.so" rel="noopener nofollow">AI Jobs Board</a>
</nav></div><button @click="showSidebar = true" class="inline-flex items-center justify-center h-10 px-0 py-2 mr-2 text-base font-medium transition-colors rounded-md hover:text-accent-foreground hover:bg-transparent md:hidden" type="button">
<svg aria-hidden="true" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M152.587 825.087q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440Zm0-203.587q-19.152 0-32.326-13.174T107.087 576q0-19.152 13.174-32.326t32.326-13.174h320q19.152 0 32.326 13.174T518.087 576q0 19.152-13.174 32.326T472.587 621.5h-320Zm0-203.587q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440ZM708.913 576l112.174 112.174q12.674 12.674 12.674 31.826t-12.674 31.826Q808.413 764.5 789.261 764.5t-31.826-12.674l-144-144Q600 594.391 600 576t13.435-31.826l144-144q12.674-12.674 31.826-12.674t31.826 12.674q12.674 12.674 12.674 31.826t-12.674 31.826L708.913 576Z"></path>
</svg>
<span class="sr-only">Toggle navigation menu</span>
</button>
<div class="flex items-center justify-between flex-1 space-x-2 sm:space-x-4 md:justify-end">
<div class="ml-4">
<a class="github-star-btn flex items-center px-3 py-2 rounded-md transition-colors rounded-md border border-gray-500 px-4" href="https://github.com/madcowd/ell" rel="noopener noreferrer" target="_blank">
<svg aria-hidden="true" class="w-5 h-5 mr-2" fill="currentColor" viewbox="0 0 24 24">
<path clip-rule="evenodd" d="M12 2C6.477 2 2 6.484 2 12.017c0 4.425 2.865 8.18 6.839 9.504.5.092.682-.217.682-.483 0-.237-.008-.868-.013-1.703-2.782.605-3.369-1.343-3.369-1.343-.454-1.158-1.11-1.466-1.11-1.466-.908-.62.069-.608.069-.608 1.003.07 1.531 1.032 1.531 1.032.892 1.53 2.341 1.088 2.91.832.092-.647.35-1.088.636-1.338-2.22-.253-4.555-1.113-4.555-4.951 0-1.093.39-1.988 1.029-2.688-.103-.253-.446-1.272.098-2.65 0 0 .84-.27 2.75 1.026A9.564 9.564 0 0112 6.844c.85.004 1.705.115 2.504.337 1.909-1.296 2.747-1.027 2.747-1.027.546 1.379.202 2.398.1 2.651.64.7 1.028 1.595 1.028 2.688 0 3.848-2.339 4.695-4.566 4.943.359.309.678.92.678 1.855 0 1.338-.012 2.419-.012 2.747 0 .268.18.58.688.482A10.019 10.019 0 0022 12.017C22 6.484 17.522 2 12 2z" fill-rule="evenodd"></path>
</svg>
<span class="font-medium">Star on GitHub</span>
<span class="ml-2 star-count" data-stars="0" style="min-width: 3ch; text-align: center;">0</span>
</a>
</div>
<script>
    document.addEventListener('DOMContentLoaded', function() {
      const starBtn = document.querySelector('.github-star-btn');
      const starCount = starBtn.querySelector('.star-count');
      
      fetch('https://api.github.com/repos/madcowd/ell')
        .then(response => response.json())
        .then(data => {
          const stars = data.stargazers_count;
          animateValue(starCount, 0, stars, 1500);
        })
        .catch(error => console.error('Error fetching GitHub stars:', error));
    });

    function animateValue(obj, start, end, duration) {
      let startTimestamp = null;
      const step = (timestamp) => {
        if (!startTimestamp) startTimestamp = timestamp;
        const progress = Math.min((timestamp - startTimestamp) / duration, 1);
        obj.textContent = Math.floor(progress * (end - start) + start);
        obj.setAttribute('data-stars', obj.textContent);
        if (progress < 1) {
          window.requestAnimationFrame(step);
        }
      };
      window.requestAnimationFrame(step);
    }

  </script>
<div class="flex-1 w-full md:w-auto md:flex-none"><form @keydown.k.window.meta="$refs.search.focus()" action="../search.html" class="relative flex items-center group" id="searchbox" method="get">
<input aria-label="Search the docs" class="inline-flex items-center font-medium transition-colors bg-transparent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 ring-offset-background border border-input hover:bg-accent focus:bg-accent hover:text-accent-foreground focus:text-accent-foreground hover:placeholder-accent-foreground py-2 px-4 relative h-9 w-full justify-start rounded-[0.5rem] text-sm text-muted-foreground sm:pr-12 md:w-40 lg:w-64" id="search-input" name="q" placeholder="Search ..." type="search" x-ref="search"/>
<kbd class="pointer-events-none absolute right-1.5 top-2 hidden h-5 select-none text-muted-foreground items-center gap-1 rounded border border-border bg-muted px-1.5 font-mono text-[10px] font-medium opacity-100 sm:flex group-hover:bg-accent group-hover:text-accent-foreground">
<span class="text-xs">⌘</span>
    K
  </kbd>
</form>
</div>
<nav class="flex items-center space-x-1">
<a href="https://github.com/MadcowD/ell" rel="noopener nofollow" title="Visit GitHub">
<div class="inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md disabled:opacity-50 disabled:pointer-events-none hover:bg-accent hover:text-accent-foreground h-9 w-9">
<svg fill="currentColor" height="18" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 0C5.373 0 0 5.373 0 12c0 5.302 3.438 9.8 8.205 11.387.6.111.82-.261.82-.577 0-.285-.01-1.04-.015-2.04-3.338.726-4.042-1.61-4.042-1.61-.546-1.387-1.333-1.757-1.333-1.757-1.09-.745.083-.729.083-.729 1.205.084 1.84 1.238 1.84 1.238 1.07 1.835 2.807 1.305 3.492.998.108-.775.418-1.305.76-1.605-2.665-.305-5.466-1.332-5.466-5.93 0-1.31.467-2.38 1.235-3.22-.125-.303-.535-1.523.115-3.176 0 0 1.005-.322 3.3 1.23.955-.265 1.98-.398 3-.403 1.02.005 2.045.138 3 .403 2.28-1.552 3.285-1.23 3.285-1.23.655 1.653.245 2.873.12 3.176.77.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.62-5.475 5.92.43.37.81 1.1.81 2.22 0 1.605-.015 2.895-.015 3.285 0 .32.215.694.825.575C20.565 21.795 24 17.3 24 12c0-6.627-5.373-12-12-12z"></path></svg>
</div>
</a>
<a href="https://discord.gg/vWntgU52Xb" rel="noopener nofollow" title="Visit Discord">
<div class="inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md disabled:opacity-50 disabled:pointer-events-none hover:bg-accent hover:text-accent-foreground h-9 w-9">
<svg fill="currentColor" height="18" viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><path d="M524.5 69.8a1.5 1.5 0 0 0 -.8-.7A485.1 485.1 0 0 0 404.1 32a1.8 1.8 0 0 0 -1.9 .9 337.5 337.5 0 0 0 -14.9 30.6 447.8 447.8 0 0 0 -134.4 0 309.5 309.5 0 0 0 -15.1-30.6 1.9 1.9 0 0 0 -1.9-.9A483.7 483.7 0 0 0 116.1 69.1a1.7 1.7 0 0 0 -.8 .7C39.1 183.7 18.2 294.7 28.4 404.4a2 2 0 0 0 .8 1.4A487.7 487.7 0 0 0 176 479.9a1.9 1.9 0 0 0 2.1-.7A348.2 348.2 0 0 0 208.1 430.4a1.9 1.9 0 0 0 -1-2.6 321.2 321.2 0 0 1 -45.9-21.9 1.9 1.9 0 0 1 -.2-3.1c3.1-2.3 6.2-4.7 9.1-7.1a1.8 1.8 0 0 1 1.9-.3c96.2 43.9 200.4 43.9 295.5 0a1.8 1.8 0 0 1 1.9 .2c2.9 2.4 6 4.9 9.1 7.2a1.9 1.9 0 0 1 -.2 3.1 301.4 301.4 0 0 1 -45.9 21.8 1.9 1.9 0 0 0 -1 2.6 391.1 391.1 0 0 0 30 48.8 1.9 1.9 0 0 0 2.1 .7A486 486 0 0 0 610.7 405.7a1.9 1.9 0 0 0 .8-1.4C623.7 277.6 590.9 167.5 524.5 69.8zM222.5 337.6c-29 0-52.8-26.6-52.8-59.2S193.1 219.1 222.5 219.1c29.7 0 53.3 26.8 52.8 59.2C275.3 311 251.9 337.6 222.5 337.6zm195.4 0c-29 0-52.8-26.6-52.8-59.2S388.4 219.1 417.9 219.1c29.7 0 53.3 26.8 52.8 59.2C470.7 311 447.5 337.6 417.9 337.6z"></path></svg>
</div>
</a>
<button @click="darkMode = darkMode === 'light' ? 'dark' : 'light'" aria-label="Color theme switcher" class="relative inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md hover:bg-accent hover:text-accent-foreground h-9 w-9" type="button">
<svg class="absolute transition-all scale-100 rotate-0 dark:-rotate-90 dark:scale-0" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 685q45.456 0 77.228-31.772Q589 621.456 589 576q0-45.456-31.772-77.228Q525.456 467 480 467q-45.456 0-77.228 31.772Q371 530.544 371 576q0 45.456 31.772 77.228Q434.544 685 480 685Zm0 91q-83 0-141.5-58.5T280 576q0-83 58.5-141.5T480 376q83 0 141.5 58.5T680 576q0 83-58.5 141.5T480 776ZM80 621.5q-19.152 0-32.326-13.174T34.5 576q0-19.152 13.174-32.326T80 530.5h80q19.152 0 32.326 13.174T205.5 576q0 19.152-13.174 32.326T160 621.5H80Zm720 0q-19.152 0-32.326-13.174T754.5 576q0-19.152 13.174-32.326T800 530.5h80q19.152 0 32.326 13.174T925.5 576q0 19.152-13.174 32.326T880 621.5h-80Zm-320-320q-19.152 0-32.326-13.174T434.5 256v-80q0-19.152 13.174-32.326T480 130.5q19.152 0 32.326 13.174T525.5 176v80q0 19.152-13.174 32.326T480 301.5Zm0 720q-19.152 0-32.326-13.17Q434.5 995.152 434.5 976v-80q0-19.152 13.174-32.326T480 850.5q19.152 0 32.326 13.174T525.5 896v80q0 19.152-13.174 32.33-13.174 13.17-32.326 13.17ZM222.174 382.065l-43-42Q165.5 327.391 166 308.239t13.174-33.065q13.435-13.674 32.587-13.674t32.065 13.674l42.239 43q12.674 13.435 12.555 31.706-.12 18.272-12.555 31.946-12.674 13.674-31.445 13.413-18.772-.261-32.446-13.174Zm494 494.761-42.239-43q-12.674-13.435-12.674-32.087t12.674-31.565Q686.609 756.5 705.38 757q18.772.5 32.446 13.174l43 41.761Q794.5 824.609 794 843.761t-13.174 33.065Q767.391 890.5 748.239 890.5t-32.065-13.674Zm-42-494.761Q660.5 369.391 661 350.62q.5-18.772 13.174-32.446l41.761-43Q728.609 261.5 747.761 262t33.065 13.174q13.674 13.435 13.674 32.587t-13.674 32.065l-43 42.239q-13.435 12.674-31.706 12.555-18.272-.12-31.946-12.555Zm-495 494.761Q165.5 863.391 165.5 844.239t13.674-32.065l43-42.239q13.435-12.674 32.087-12.674t31.565 12.674Q299.5 782.609 299 801.38q-.5 18.772-13.174 32.446l-41.761 43Q231.391 890.5 212.239 890t-33.065-13.174ZM480 576Z"></path>
</svg>
<svg class="absolute transition-all scale-0 rotate-90 dark:rotate-0 dark:scale-100" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 936q-151 0-255.5-104.5T120 576q0-138 90-239.5T440 218q25-3 39 18t-1 44q-17 26-25.5 55t-8.5 61q0 90 63 153t153 63q31 0 61.5-9t54.5-25q21-14 43-1.5t19 39.5q-14 138-117.5 229T480 936Zm0-80q88 0 158-48.5T740 681q-20 5-40 8t-40 3q-123 0-209.5-86.5T364 396q0-20 3-40t8-40q-78 32-126.5 102T200 576q0 116 82 198t198 82Zm-10-270Z"></path>
</svg>
</button>
</nav>
</div>
</div>
</header>
<div class="flex-1"><div class="container flex-1 items-start md:grid md:grid-cols-[220px_minmax(0,1fr)] md:gap-6 lg:grid-cols-[240px_minmax(0,1fr)] lg:gap-10"><aside :aria-hidden="!showSidebar" :class="{ 'translate-x-0': showSidebar }" class="fixed inset-y-0 left-0 md:top-14 z-50 md:z-30 bg-background md:bg-transparent transition-all duration-100 -translate-x-full md:translate-x-0 ml-0 p-6 md:p-0 md:-ml-2 md:h-[calc(100vh-3.5rem)] w-5/6 md:w-full shrink-0 overflow-y-auto border-r border-border md:sticky" id="left-sidebar">
<a class="!justify-start text-sm md:!hidden bg-background" href="../index.html">
<img alt="Logo" class="mr-2 hidden dark:block" height="16" src="../_static/ell-wide-dark.png" width="16"/>
<img alt="Logo" class="mr-2 dark:hidden" height="16" src="../_static/ell-wide-light.png" width="16"/><span class="font-bold text-clip whitespace-nowrap">ell  documentation</span>
</a>
<div class="relative overflow-hidden md:overflow-auto my-4 md:my-0 h-[calc(100vh-8rem)] md:h-auto">
<div class="overflow-y-auto h-full w-full relative pr-6"><nav class="flex md:hidden flex-col font-medium mt-4">
<a href="../index.html">Docs</a>
<a href="../reference/index.html">API Reference</a>
<a href="https://jobs.ell.so" rel="nofollow noopener">AI Jobs Board</a>
</nav><nav class="table w-full min-w-full my-6 lg:my-8">
<p class="caption" role="heading"><span class="caption-text">The Basics:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting Started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Core Concepts:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">@ell.simple</a></li>
<li class="toctree-l1"><a class="reference internal" href="versioning_and_storage.html">Versioning &amp; Tracing</a></li>
<li class="toctree-l1"><a class="reference internal" href="ell_studio.html">Studio</a></li>
<li class="toctree-l1"><a class="reference internal" href="message_api.html">Messages</a></li>
<li class="toctree-l1"><a class="reference internal" href="ell_complex.html">@ell.complex</a></li>
<li class="toctree-l1"><a class="reference internal" href="tool_usage.html">Tool Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="structured_outputs.html">Structured Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="multimodality.html">Multimodality</a></li>
<li class="toctree-l1"><a class="reference internal" href="models_and_api_clients.html">Models &amp; API Clients</a></li>
<li class="toctree-l1"><a class="reference internal" href="configuration.html">Configuration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">ell package</a></li>
</ul>
</nav>
</div>
</div>
<button @click="showSidebar = false" class="absolute md:hidden right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100" type="button">
<svg class="h-4 w-4" fill="currentColor" height="24" stroke="none" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 632 284 828q-11 11-28 11t-28-11q-11-11-11-28t11-28l196-196-196-196q-11-11-11-28t11-28q11-11 28-11t28 11l196 196 196-196q11-11 28-11t28 11q11 11 11 28t-11 28L536 576l196 196q11 11 11 28t-11 28q-11 11-28 11t-28-11L480 632Z"></path>
</svg>
</button>
</aside>
<main class="relative py-6 lg:gap-10 lg:py-8 xl:grid xl:grid-cols-[1fr_300px]">
<div class="w-full min-w-0 mx-auto">
<nav aria-label="breadcrumbs" class="flex items-center mb-4 space-x-1 text-sm text-muted-foreground">
<a class="overflow-hidden text-ellipsis whitespace-nowrap hover:text-foreground" href="../index.html">
<span class="hidden md:inline">ell  documentation</span>
<svg aria-label="Home" class="md:hidden" fill="currentColor" height="18" stroke="none" viewbox="0 96 960 960" width="18" xmlns="http://www.w3.org/2000/svg">
<path d="M240 856h120V616h240v240h120V496L480 316 240 496v360Zm-80 80V456l320-240 320 240v480H520V696h-80v240H160Zm320-350Z"></path>
</svg>
</a>
<div class="mr-1">/</div><span aria-current="page" class="font-medium text-foreground overflow-hidden text-ellipsis whitespace-nowrap">@ell.simple</span>
</nav>
<div id="content" role="main">
<section id="ell-simple">
<h1>@ell.simple<a class="headerlink" href="#ell-simple" title="Link to this heading">¶</a></h1>
<p>The core unit of prompt engineering in ell is the <code class="docutils literal notranslate"><span class="pre">@ell.simple</span></code> decorator. This decorator transforms a function that provides system and user prompts into a callable object. When invoked, this callable sends the provided prompts to a language model and returns the model’s response.</p>
<p>The development of <code class="docutils literal notranslate"><span class="pre">@ell.simple</span></code> is driven by several important objectives:</p>
<ul class="simple">
<li><p>Improve readability and usabiltiy of prompt engineering code.</p></li>
<li><p>Force a functional decomposition of prompt systems into reusable components.</p></li>
<li><p>Enable versioning, serialization, and tracking of prompts over time</p></li>
</ul>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#usage'">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">@ell.simple</span></code> decorator can be used in two main ways:</p>
<ol class="arabic">
<li><p>Using the docstring as the system prompt, and the return value as the user message:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="nd">@ell</span><span class="o">.</span><span class="n">simple</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-4"</span><span class="p">)</span>
</span><span id="line-2"><span class="k">def</span> <span class="nf">hello</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="line-3"><span class="w">    </span><span class="sd">"""You are a helpful assistant."""</span>
</span><span id="line-4">    <span class="k">return</span> <span class="sa">f</span><span class="s2">"Say hello to </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">!"</span>
</span></code></pre></div>
</div>
</li>
<li><p>Explicitly defining messages:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="nd">@ell</span><span class="o">.</span><span class="n">simple</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-4"</span><span class="p">)</span>
</span><span id="line-2"><span class="k">def</span> <span class="nf">hello</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="line-3">    <span class="k">return</span> <span class="p">[</span>
</span><span id="line-4">        <span class="n">ell</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s2">"You are a helpful assistant."</span><span class="p">),</span>
</span><span id="line-5">        <span class="n">ell</span><span class="o">.</span><span class="n">user</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Say hello to </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">!"</span><span class="p">)</span>
</span><span id="line-6">    <span class="p">]</span>
</span></code></pre></div>
</div>
</li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Messages in ell are not the same as the dictionary messages used in the OpenAI API. ell’s Message API provides a more intuitive and flexible way to construct and manipulate messages. You can read more about ell’s Message API and type coercion in the <a class="reference internal" href="message_api.html"><span class="doc">Messages</span></a> page.</p>
</div>
<section id="invoking-an-ell-simple-lmp">
<h3>Invoking an <code class="docutils literal notranslate"><span class="pre">ell.simple</span></code> LMP<a class="headerlink" href="#invoking-an-ell-simple-lmp" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#invoking-an-ell-simple-lmp'">¶</a></h3>
<p>To use the decorated function, we can call it as a normal function. However, instead of receiving the typical return value, we will receive the result of passing the system and user prompts directly to the model specified in the decorator constructor, in this case GPT-4.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">hello</span><span class="p">(</span><span class="s2">"world"</span><span class="p">)</span>
</span><span id="line-2"><span class="go">'Hello, world!'</span>
</span></code></pre></div>
</div>
<p>As you can see from this example, the return type of an <code class="docutils literal notranslate"><span class="pre">ell.simple</span></code> LMP is a string. This is to optimize for readability and usability, as most invocations of language models revolve around passing strings around. Additional metadata is only needed occasionally.</p>
<p>Therefore, we have two decorators within the ell framework:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">@ell.simple</span></code>: Returns simple strings, as shown here.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">@ell.complex</span></code>: Returns message objects containing all of the typical message API metadata and additional helper functions for interacting with multimodal output data. You can read more about this in the <a class="reference internal" href="ell_complex.html"><span class="doc">@ell.complex</span></a> page.</p></li>
</ol>
</section>
<section id="variable-system-prompts">
<h3>Variable system prompts<a class="headerlink" href="#variable-system-prompts" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#variable-system-prompts'">¶</a></h3>
<p>One of the challenges with specifying the system prompt in the docstring of a language model program is that if you want to use variable system prompts, Python will no longer treat the string literal at the top of the function as a docstring. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="k">def</span> <span class="nf">my_func</span><span class="p">(</span><span class="n">var</span> <span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
</span><span id="line-2">    <span class="sa">f</span><span class="s2">"""my variable doc string for my_func. </span><span class="si">{</span><span class="n">var</span><span class="si">}</span><span class="s2">"""</span>
</span><span id="line-3">    <span class="k">pass</span>
</span></code></pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">my_func</span><span class="o">.</span><span class="vm">__doc__</span>
</span><span id="line-2"><span class="go">None</span>
</span></code></pre></div>
</div>
<p>This behavior makes sense because a function’s docstring should not change during execution and should be extractable through static analysis.</p>
<p>To address this issue with <code class="docutils literal notranslate"><span class="pre">@ell.simple</span></code>, you need to use the second method of defining an <code class="docutils literal notranslate"><span class="pre">ell.simple</span></code> language model program by creating a function that returns a list of messages (see <a class="reference internal" href="message_api.html"><span class="doc">Messages</span></a> for more details).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="nd">@ell</span><span class="o">.</span><span class="n">simple</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-4"</span><span class="p">)</span>
</span><span id="line-2"><span class="k">def</span> <span class="nf">my_func</span><span class="p">(</span><span class="n">name</span> <span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">var</span> <span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
</span><span id="line-3">    <span class="k">return</span> <span class="p">[</span>
</span><span id="line-4">        <span class="n">ell</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="sa">f</span><span class="s2">"You are a helpful assistant. </span><span class="si">{</span><span class="n">var</span><span class="si">}</span><span class="s2">"</span><span class="p">),</span>
</span><span id="line-5">        <span class="n">ell</span><span class="o">.</span><span class="n">user</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Say hello to </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">!"</span><span class="p">)</span>
</span><span id="line-6">    <span class="p">]</span>
</span></code></pre></div>
</div>
<p>With this approach, ell will ignore the docstring of <code class="docutils literal notranslate"><span class="pre">my_func</span></code> and instead supply the messages returned by the function to the language model API.</p>
</section>
<section id="passing-parameters-to-an-llm-api">
<h3>Passing parameters to an LLM API<a class="headerlink" href="#passing-parameters-to-an-llm-api" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#passing-parameters-to-an-llm-api'">¶</a></h3>
<p>One of the most convenient functions of the <code class="docutils literal notranslate"><span class="pre">@ell.simple</span></code> decorator is that you can easily pass parameters to an LLM API, both at definition time and runtime. For example, models within the OpenAI API have parameters like <code class="docutils literal notranslate"><span class="pre">temperature</span></code>, <code class="docutils literal notranslate"><span class="pre">max_tokens</span></code>, stop tokens, and <code class="docutils literal notranslate"><span class="pre">logit_bias</span></code>. Due to how <code class="docutils literal notranslate"><span class="pre">@ell.simple</span></code> works, you can simply specify these in the decorator as keyword arguments.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="nd">@ell</span><span class="o">.</span><span class="n">simple</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-4"</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="p">[</span><span class="s2">"."</span><span class="p">])</span>
</span><span id="line-2"><span class="k">def</span> <span class="nf">hello</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="line-3"><span class="w">    </span><span class="sd">"""You are a helpful assistant."""</span>
</span><span id="line-4">    <span class="k">return</span> <span class="sa">f</span><span class="s2">"Hey there </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">!"</span>
</span></code></pre></div>
</div>
<p>Likewise, if you want to modify those parameters for a particular invocation of that prompt, you simply pass them in as <code class="docutils literal notranslate"><span class="pre">lm_params</span></code> keyword arguments to the function when calling it. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">hello</span><span class="p">(</span><span class="s2">"world"</span><span class="p">,</span> <span class="n">lm_params</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">))</span>
</span><span id="line-2"><span class="go">'Hey there world!'</span>
</span></code></pre></div>
</div>
<section id="multiple-outputs-n-1">
<h4>Multiple outputs (n&gt;1)<a class="headerlink" href="#multiple-outputs-n-1" title="Link to this heading">¶</a></h4>
<p>As is often important in prompt engineering to leverage test-time compute, many language model APIs allow you to specify a count parameter, usually ‘n’, which will generate several outputs from the language model given a particular prompt.</p>
<p>In the OpenAI API, for example, this is actually quite cumbersome because the API specification separates different completions into ‘choices’ objects. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">Completion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="line-2">    <span class="n">model</span><span class="o">=</span><span class="s2">"gpt-4"</span><span class="p">,</span>
</span><span id="line-3">    <span class="n">prompt</span><span class="o">=</span><span class="s2">"Say hello to everyone"</span><span class="p">,</span>
</span><span id="line-4">    <span class="n">n</span><span class="o">=</span><span class="mi">2</span>
</span><span id="line-5"><span class="p">)</span>
</span><span id="line-6">
</span><span id="line-7"><span class="n">r1</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
</span><span id="line-8"><span class="n">r2</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
</span></code></pre></div>
</div>
<p>In the spirit of simplicity, we’ve designed it to automatically coerce the return type into the correct shape, similar to NumPy and PyTorch. This means that when you call an <code class="docutils literal notranslate"><span class="pre">ell.simple</span></code> language model program with <code class="docutils literal notranslate"><span class="pre">n</span></code> greater than one, instead of returning a string, it returns a list of strings.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="nd">@ell</span><span class="o">.</span><span class="n">simple</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-4"</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="line-2"><span class="k">def</span> <span class="nf">hello</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="line-3"><span class="w">    </span><span class="sd">"""You are a helpful assistant."""</span>
</span><span id="line-4">    <span class="k">return</span> <span class="sa">f</span><span class="s2">"Say hello to </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">!"</span>
</span></code></pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">hello</span><span class="p">(</span><span class="s2">"world"</span><span class="p">)</span>
</span><span id="line-2"><span class="go">['Hey there world!', 'Hi, world.']</span>
</span></code></pre></div>
</div>
<p>Similarly, this behavior applies when using runtime <code class="docutils literal notranslate"><span class="pre">lm_params</span></code> to specify multiple outputs.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">hello</span><span class="p">(</span><span class="s2">"world"</span><span class="p">,</span> <span class="n">lm_params</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
</span><span id="line-2"><span class="go">['Hey there world!', 'Hi, world.', 'Hello, world!']</span>
</span></code></pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the future, we may modify this interface as preserving the <code class="docutils literal notranslate"><span class="pre">lm_params</span></code> keyword in its current form could potentially lead to conflicts with user-defined functions. However, during the beta phase, we are closely monitoring for feedback and will make adjustments based on user experiences and needs.</p>
</div>
</section>
</section>
<section id="multimodal-inputs">
<h3>Multimodal inputs<a class="headerlink" href="#multimodal-inputs" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#multimodal-inputs'">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">@ell.simple</span></code> supports multimodal inputs, allowing you to easily work with both text and images in your language model programs. This is particularly useful for models with vision capabilities, such as GPT-4 with vision.</p>
<p>Here’s an example of how to use <code class="docutils literal notranslate"><span class="pre">@ell.simple</span></code> with multimodal inputs:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
</span><span id="line-2"><span class="kn">import</span> <span class="nn">ell</span>
</span><span id="line-3">
</span><span id="line-4"><span class="nd">@ell</span><span class="o">.</span><span class="n">simple</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-4-vision-preview"</span><span class="p">)</span>
</span><span id="line-5"><span class="k">def</span> <span class="nf">describe_image</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">):</span>
</span><span id="line-6">    <span class="k">return</span> <span class="p">[</span>
</span><span id="line-7">        <span class="n">ell</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s2">"You are a helpful assistant that describes images."</span><span class="p">),</span>
</span><span id="line-8">        <span class="n">ell</span><span class="o">.</span><span class="n">user</span><span class="p">([</span><span class="s2">"What's in this image?"</span><span class="p">,</span> <span class="n">image</span><span class="p">])</span>
</span><span id="line-9">    <span class="p">]</span>
</span><span id="line-10">
</span><span id="line-11"><span class="c1"># Usage</span>
</span><span id="line-12"><span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"path/to/your/image.jpg"</span><span class="p">)</span>
</span><span id="line-13"><span class="n">description</span> <span class="o">=</span> <span class="n">describe_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</span><span id="line-14"><span class="nb">print</span><span class="p">(</span><span class="n">description</span><span class="p">)</span>  <span class="c1"># This will print a text description of the image</span>
</span></code></pre></div>
</div>
<p>In this example, the <code class="docutils literal notranslate"><span class="pre">describe_image</span></code> function takes a PIL Image object as input. The <code class="docutils literal notranslate"><span class="pre">ell.user</span></code> message combines both text and image inputs. <code class="docutils literal notranslate"><span class="pre">@ell.simple</span></code> automatically handles the conversion of the PIL Image object into the appropriate format for the language model.</p>
<p>This approach simplifies working with multimodal inputs, allowing you to focus on your application logic rather than the intricacies of API payloads.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>While <code class="docutils literal notranslate"><span class="pre">@ell.simple</span></code> supports multimodal inputs, it is designed to return text-only outputs. For handling multimodal outputs (such as generated images or audio), you need to use <code class="docutils literal notranslate"><span class="pre">@ell.complex</span></code>. Please refer to the <a class="reference internal" href="ell_complex.html"><span class="doc">@ell.complex</span></a> documentation for more information on working with multimodal outputs.</p>
</div>
</section>
</section>
<section id="what-about-multiturn-conversations-tools-structured-outputs-and-other-features">
<h2>What about multiturn conversations, tools, structured outputs, and other features?<a class="headerlink" href="#what-about-multiturn-conversations-tools-structured-outputs-and-other-features" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#what-about-multiturn-conversations-tools-structured-outputs-and-other-features'">¶</a></h2>
<p>While <code class="docutils literal notranslate"><span class="pre">@ell.simple</span></code> is great for straightforward text-based interactions with language models, there are scenarios where you might need more complex functionality. For instance, you may want to work with multiturn conversations, utilize tools, generate structured outputs, or handle multimodal content beyond just text.</p>
<p>In such cases, you’ll need an LMP that can return rich <code class="docutils literal notranslate"><span class="pre">Message</span></code> objects instead of just strings. This is where <code class="docutils literal notranslate"><span class="pre">@ell.complex</span></code> comes into play. The <code class="docutils literal notranslate"><span class="pre">@ell.complex</span></code> decorator provides enhanced capabilities for more sophisticated interactions with language models.</p>
<p>For more information on how to use <code class="docutils literal notranslate"><span class="pre">@ell.complex</span></code> and its advanced features, please refer to the <a class="reference internal" href="ell_complex.html"><span class="doc">@ell.complex</span></a> documentation.</p>
</section>
<section id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#reference'">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="ell.simple">
<span class="sig-prename descclassname"><span class="pre">ell.</span></span><span class="sig-name descname"><span class="pre">simple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">OpenAI</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exempt_from_tracking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">api_params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ell.simple" title="Link to this definition" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#ell.simple'">¶</a></dt>
<dd><p>The fundamental unit of language model programming in ell.</p>
<p>This decorator simplifies the process of creating Language Model Programs (LMPs)
that return text-only outputs from language models, while supporting multimodal inputs.
It wraps the more complex ‘complex’ decorator, providing a streamlined interface for common use cases.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>str</em>) – The name or identifier of the language model to use.</p></li>
<li><p><strong>client</strong> (<em>Optional</em><em>[</em><em>openai.Client</em><em>]</em>) – An optional OpenAI client instance. If not provided, a default client will be used.</p></li>
<li><p><strong>exempt_from_tracking</strong> (<em>bool</em>) – If True, the LMP usage won’t be tracked. Default is False.</p></li>
<li><p><strong>api_params</strong> (<em>Any</em>) – Additional keyword arguments to pass to the underlying API call.</p></li>
</ul>
</dd>
</dl>
<p>Usage:
The decorated function can return either a single prompt or a list of ell.Message objects:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="nd">@ell</span><span class="o">.</span><span class="n">simple</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-4"</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
</span><span id="line-2"><span class="k">def</span> <span class="nf">summarize_text</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="line-3"><span class="w">    </span><span class="sd">'''You are an expert at summarizing text.'''</span> <span class="c1"># System prompt</span>
</span><span id="line-4">    <span class="k">return</span> <span class="sa">f</span><span class="s2">"Please summarize the following text:</span><span class="se">\n\n</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">"</span> <span class="c1"># User prompt</span>
</span><span id="line-5">
</span><span id="line-6">
</span><span id="line-7"><span class="nd">@ell</span><span class="o">.</span><span class="n">simple</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-4"</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
</span><span id="line-8"><span class="k">def</span> <span class="nf">describe_image</span><span class="p">(</span><span class="n">image</span> <span class="p">:</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ell</span><span class="o">.</span><span class="n">Message</span><span class="p">]:</span>
</span><span id="line-9"><span class="w">    </span><span class="sd">'''Describe the contents of an image.'''</span> <span class="c1"># unused because we're returning a list of Messages</span>
</span><span id="line-10">    <span class="k">return</span> <span class="p">[</span>
</span><span id="line-11">        <span class="c1"># helper function for ell.Message(text="...", role="system")</span>
</span><span id="line-12">        <span class="n">ell</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s2">"You are an AI trained to describe images."</span><span class="p">),</span>
</span><span id="line-13">        <span class="c1"># helper function for ell.Message(content="...", role="user")</span>
</span><span id="line-14">        <span class="n">ell</span><span class="o">.</span><span class="n">user</span><span class="p">([</span><span class="s2">"Describe this image in detail."</span><span class="p">,</span> <span class="n">image</span><span class="p">]),</span>
</span><span id="line-15">    <span class="p">]</span>
</span><span id="line-16">
</span><span id="line-17">
</span><span id="line-18"><span class="n">image_description</span> <span class="o">=</span> <span class="n">describe_image</span><span class="p">(</span><span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"https://example.com/image.jpg"</span><span class="p">))</span>
</span><span id="line-19"><span class="nb">print</span><span class="p">(</span><span class="n">image_description</span><span class="p">)</span>
</span><span id="line-20"><span class="c1"># Output will be a string text-only description of the image</span>
</span><span id="line-21">
</span><span id="line-22"><span class="n">summary</span> <span class="o">=</span> <span class="n">summarize_text</span><span class="p">(</span><span class="s2">"Long text to summarize..."</span><span class="p">)</span>
</span><span id="line-23"><span class="nb">print</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>
</span><span id="line-24"><span class="c1"># Output will be a text-only summary</span>
</span></code></pre></div>
</div>
<p>Notes:</p>
<ul class="simple">
<li><p>This decorator is designed for text-only model outputs, but supports multimodal inputs.</p></li>
<li><p>It simplifies complex responses from language models to text-only format, regardless of
the model’s capability for structured outputs, function calling, or multimodal outputs.</p></li>
<li><p>For preserving complex model outputs (e.g., structured data, function calls, or multimodal
outputs), use the @ell.complex decorator instead. @ell.complex returns a Message object (role=’assistant’)</p></li>
<li><p>The decorated function can return a string or a list of ell.Message objects for more
complex prompts, including multimodal inputs.</p></li>
<li><p>If called with n &gt; 1 in api_params, the wrapped LMP will return a list of strings for the n parallel outputs
of the model instead of just one string. Otherwise, it will return a single string.</p></li>
<li><p>You can pass LM API parameters either in the decorator or when calling the decorated function.
Parameters passed during the function call will override those set in the decorator.</p></li>
</ul>
<p>Example of passing LM API params:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="nd">@ell</span><span class="o">.</span><span class="n">simple</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-4"</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
</span><span id="line-2"><span class="k">def</span> <span class="nf">generate_story</span><span class="p">(</span><span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="line-3">    <span class="k">return</span> <span class="sa">f</span><span class="s2">"Write a short story based on this prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2">"</span>
</span><span id="line-4">
</span><span id="line-5"><span class="c1"># Using default parameters</span>
</span><span id="line-6"><span class="n">story1</span> <span class="o">=</span> <span class="n">generate_story</span><span class="p">(</span><span class="s2">"A day in the life of a time traveler"</span><span class="p">)</span>
</span><span id="line-7">
</span><span id="line-8"><span class="c1"># Overriding parameters during function call</span>
</span><span id="line-9"><span class="n">story2</span> <span class="o">=</span> <span class="n">generate_story</span><span class="p">(</span><span class="s2">"An AI's first day of consciousness"</span><span class="p">,</span> <span class="n">lm_params</span><span class="o">=</span><span class="p">{</span><span class="s2">"temperature"</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span> <span class="s2">"max_tokens"</span><span class="p">:</span> <span class="mi">500</span><span class="p">})</span>
</span></code></pre></div>
</div>
<p>See Also:</p>
<ul class="simple">
<li><p><a class="reference internal" href="ell_complex.html#ell.complex" title="ell.complex"><code class="xref py py-func docutils literal notranslate"><span class="pre">ell.complex()</span></code></a>: For LMPs that preserve full structure of model responses, including multimodal outputs.</p></li>
<li><p><code class="xref py py-func docutils literal notranslate"><span class="pre">ell.tool()</span></code>: For defining tools that can be used within complex LMPs.</p></li>
<li><p><code class="xref py py-mod docutils literal notranslate"><span class="pre">ell.studio</span></code>: For visualizing and analyzing LMP executions.</p></li>
</ul>
</dd></dl>
</section>
</section>
</div><div class="flex justify-between items-center pt-6 mt-12 border-t border-border gap-4">
<div class="mr-auto">
<a class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors border border-input hover:bg-accent hover:text-accent-foreground py-2 px-4" href="../getting_started.html">
<svg class="mr-2 h-4 w-4" fill="none" height="24" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<polyline points="15 18 9 12 15 6"></polyline>
</svg>
        Getting Started
      </a>
</div>
<div class="ml-auto">
<a class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors border border-input hover:bg-accent hover:text-accent-foreground py-2 px-4" href="versioning_and_storage.html">
        Versioning &amp; Tracing
        <svg class="ml-2 h-4 w-4" fill="none" height="24" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<polyline points="9 18 15 12 9 6"></polyline>
</svg>
</a>
</div>
</div></div><aside class="hidden text-sm xl:block" id="right-sidebar">
<div class="sticky top-16 -mt-10 max-h-[calc(100vh-5rem)] overflow-y-auto pt-6 space-y-2"><p class="font-medium">On this page</p>
<ul>
<li><a :data-current="activeSection === '#usage'" class="reference internal" href="#usage">Usage</a><ul>
<li><a :data-current="activeSection === '#invoking-an-ell-simple-lmp'" class="reference internal" href="#invoking-an-ell-simple-lmp">Invoking an <code class="docutils literal notranslate"><span class="pre">ell.simple</span></code> LMP</a></li>
<li><a :data-current="activeSection === '#variable-system-prompts'" class="reference internal" href="#variable-system-prompts">Variable system prompts</a></li>
<li><a :data-current="activeSection === '#passing-parameters-to-an-llm-api'" class="reference internal" href="#passing-parameters-to-an-llm-api">Passing parameters to an LLM API</a><ul>
<li><a :data-current="activeSection === '#multiple-outputs-n-1'" class="reference internal" href="#multiple-outputs-n-1">Multiple outputs (n&gt;1)</a></li>
</ul>
</li>
<li><a :data-current="activeSection === '#multimodal-inputs'" class="reference internal" href="#multimodal-inputs">Multimodal inputs</a></li>
</ul>
</li>
<li><a :data-current="activeSection === '#what-about-multiturn-conversations-tools-structured-outputs-and-other-features'" class="reference internal" href="#what-about-multiturn-conversations-tools-structured-outputs-and-other-features">What about multiturn conversations, tools, structured outputs, and other features?</a></li>
<li><a :data-current="activeSection === '#reference'" class="reference internal" href="#reference">Reference</a><ul>
<li><a :data-current="activeSection === '#ell.simple'" class="reference internal" href="#ell.simple"><code class="docutils literal notranslate"><span class="pre">simple()</span></code></a></li>
</ul>
</li>
</ul>
</div>
</aside>
</main>
</div>
</div><footer class="py-6 border-t border-border md:py-0">
<div class="container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row">
<div class="flex flex-col items-center gap-4 px-8 md:flex-row md:gap-2 md:px-0">
<p class="text-sm leading-loose text-center text-muted-foreground md:text-left">© 2024, William Guss Built with <a class="font-medium underline underline-offset-4" href="https://www.sphinx-doc.org" rel="noreferrer">Sphinx 7.2.6</a></p>
</div>
</div>
</footer>
</div>
<script src="../_static/documentation_options.js?v=5929fcd5"></script>
<script src="../_static/doctools.js?v=888ff710"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script defer="defer" src="../_static/theme.js?v=e82a16a3"></script>
</body>
</html>