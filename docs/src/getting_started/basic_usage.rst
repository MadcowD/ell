Basic Usage
===========

This guide will walk you through creating and running your first Language Model Program (LMP) using ell. We'll start with a simple example and gradually introduce more features.

Creating Your First Language Model Program
------------------------------------------

Let's create a simple LMP that generates a short story based on a given prompt.

.. code-block:: python

    import ell

    @ell.simple(model="gpt-4")
    def generate_story(prompt: str) -> str:
        """You are a helpful AI assistant."""
        return f"Write a short story based on this prompt: {prompt}"

    # Use the LMP
    story = generate_story("A time traveler's first day in the future")
    print(story)

Let's break down this example:

1. We import the ``ell`` library.
2. We define a function called ``generate_story`` and decorate it with ``@ell.simple``.
3. The decorator specifies that we want to use the "gpt-4" model.
4. Our function takes a ``prompt`` as input and returns a string.
5. The function's docstring becomes the system prompt for the language model.
6. The return value of the function becomes the user prompt.
7. We call the function with a prompt and print the result.

Understanding the Output
------------------------

When you run this code, ell will:

1. Construct the full prompt by combining the system prompt (the docstring) and the user prompt (the return value of the function).
2. Send this prompt to the specified language model (in this case, GPT-4).
3. Receive the generated text from the model.
4. Return this text as the result of the ``generate_story`` function call.

The output you see will be a short story generated by the language model based on the prompt you provided.

Using Verbose Mode
--------------------

Before using ell in a project, it's a good practice to set up some basic configuration. Here's how you can do that:

.. code-block:: python

    import ell

    ell.init(verbose=True)

    @ell.simple(model="gpt-4")
    def generate_story(prompt: str) -> str:
        """You are a helpful AI assistant."""
        return f"Write a short story based on this prompt: {prompt}"

    # Use the LMP
    story = generate_story("A time traveler's first day in the future")
    print(story)
    # Your LMPs and code here...

This configuration:

- Sets up a local storage directory for versioning and tracing.
- Enables verbose output for more detailed logging.
- Turns on autocommit for automatic saving of versions and traces.

Next Steps
----------

You've now created your first Language Model Program with ell! From here, you can explore more advanced features such as:

- Using the ``@ell.complex`` decorator for multi-turn conversations and tool use.
- Working with structured inputs and outputs.
- Integrating multimodal inputs like images.
- Leveraging ell's versioning and tracing capabilities.

Check out the Core Concepts section to dive deeper into these topics.

   
   